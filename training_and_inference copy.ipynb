{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce GTX 1660 Ti for training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Exiting...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "print(f\"Using {device_name} for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install segmentation-models-pytorch\n",
    "# !pip install piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import PIL\n",
    "# from torchvision.models import resnet34\n",
    "# from torchvision.models.segmentation import fcn_resnet50\n",
    "import segmentation_models_pytorch as smp\n",
    "import piq\n",
    "# import albumentations as A  # Alternative for augmentations like `imutils`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: NVIDIA GeForce GTX 1660 Ti\n",
      "35481 15207\n",
      "654\n",
      "Epoch [1/15], Loss: 0.35141370142495126\n",
      "Epoch [2/15], Loss: 0.3012414204848576\n",
      "Epoch [3/15], Loss: 0.23960456902428293\n",
      "Epoch [4/15], Loss: 0.21680632741522207\n",
      "Epoch [5/15], Loss: 0.20531339516125896\n",
      "Epoch [6/15], Loss: 0.194852031035075\n",
      "Epoch [7/15], Loss: 0.18826026857786077\n",
      "Epoch [8/15], Loss: 0.18508590571750275\n",
      "Epoch [9/15], Loss: 0.17792110887462756\n",
      "Epoch [10/15], Loss: 0.17270606734711808\n",
      "Epoch [11/15], Loss: 0.16940810704037776\n",
      "Epoch [12/15], Loss: 0.1684297049389539\n",
      "Epoch [13/15], Loss: 0.16493337079412343\n",
      "Epoch [14/15], Loss: 0.16195789995335372\n",
      "Epoch [15/15], Loss: 0.16133070236947\n",
      "Test Loss: 0.31716150481526445\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type != 'cuda':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Constants\n",
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "INIT_LR = 0.0001\n",
    "EPOCHS = 15\n",
    "TRAIN_PATH = \"/home/river2000/monocular_depth_estimation/nyu_data/data/nyu2_train.csv\"\n",
    "TEST_PATH = \"/home/river2000/monocular_depth_estimation/nyu_data/data/nyu2_test.csv\"\n",
    "\n",
    "# Load dataset\n",
    "BASE_PATH = \"/home/river2000/monocular_depth_estimation/nyu_data/\"\n",
    "\n",
    "def read_csv(csv_file_path):\n",
    "    with open(csv_file_path, 'r') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=',')\n",
    "        return [(os.path.join(BASE_PATH, row[0]), os.path.join(BASE_PATH, row[1])) for row in csv_reader if len(row) > 0]\n",
    "\n",
    "def train_val_split(train_paths, val_size):\n",
    "    random.shuffle(train_paths)\n",
    "    len_train_paths = len(train_paths)\n",
    "    i = int(len_train_paths * (1.0 - val_size))\n",
    "    train = train_paths[0:i]\n",
    "    val = train_paths[i:len(train_paths)]\n",
    "    return train, val\n",
    "\n",
    "def load_train_paths(train_path):\n",
    "    train_paths = read_csv(train_path)\n",
    "    labels = {img_path: dm_path for img_path, dm_path in train_paths}\n",
    "    x_paths = [img_path for img_path, dm in train_paths]\n",
    "    x_train_paths, x_val_paths = train_val_split(x_paths, 0.3)\n",
    "\n",
    "    partition = {\n",
    "        'train': x_train_paths,\n",
    "        'validation': x_val_paths\n",
    "    }\n",
    "    return partition, labels\n",
    "\n",
    "def load_test_paths(test_path):\n",
    "    test_paths = read_csv(test_path)\n",
    "    labels = {img_path: dm_path for img_path, dm_path in test_paths}\n",
    "    x_paths = [img_path for img_path, dm in test_paths]\n",
    "\n",
    "    partition = {\n",
    "        'test': x_paths\n",
    "    }\n",
    "    return partition, labels\n",
    "\n",
    "# Preprocessing\n",
    "def normalize_img(img):\n",
    "    norm_img = (img - img.min()) / (img.max() - img.min())\n",
    "    return norm_img\n",
    "\n",
    "def preprocess_image(img_path, horizontal_flip=False):\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found at path: {img_path}\")\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT)).astype(\"float\")\n",
    "    image = normalize_img(image)\n",
    "\n",
    "    if horizontal_flip:\n",
    "        image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "def preprocess_depth_map(depth_map_path, horizontal_flip=False):\n",
    "    depth_map = cv2.imread(depth_map_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if depth_map is None:\n",
    "        raise FileNotFoundError(f\"Depth map not found at path: {depth_map_path}\")\n",
    "    depth_map = cv2.resize(depth_map, (WIDTH, HEIGHT)).astype(\"float\")\n",
    "    depth_map = normalize_img(depth_map)\n",
    "\n",
    "    if horizontal_flip:\n",
    "        depth_map = cv2.flip(depth_map, 1)\n",
    "\n",
    "    depth_map = np.reshape(depth_map, (depth_map.shape[0], depth_map.shape[1], 1))\n",
    "    return depth_map\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, list_IDs, labels, transform=None, pred=False):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.pred = pred\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        image = preprocess_image(ID)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.pred:\n",
    "            return image\n",
    "        depth_map = preprocess_depth_map(self.labels[ID])\n",
    "        if self.transform:\n",
    "            depth_map = self.transform(depth_map)\n",
    "        return image, depth_map\n",
    "\n",
    "# Load train and validation paths\n",
    "partition, labels = load_train_paths(TRAIN_PATH)\n",
    "print(len(partition['train']), len(partition['validation']))\n",
    "\n",
    "# Load test paths\n",
    "test_partition, test_labels = load_test_paths(TEST_PATH)\n",
    "print(len(test_partition['test']))\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_set = DepthDataset(partition['train'], labels, transform=transform)\n",
    "training_loader = DataLoader(training_set, batch_size=16, shuffle=True)\n",
    "\n",
    "validation_set = DepthDataset(partition['validation'], labels, transform=transform)\n",
    "validation_loader = DataLoader(validation_set, batch_size=16, shuffle=False)\n",
    "\n",
    "test_set = DepthDataset(test_partition['test'], test_labels, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "# Model\n",
    "model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "import torch.nn.functional as F\n",
    "import piq\n",
    "\n",
    "def depth_loss(y_true, y_pred):\n",
    "    w1, w2, w3 = 1.0, 3.0, 0.1\n",
    "\n",
    "    l_depth = torch.mean(torch.abs(y_pred - y_true))\n",
    "\n",
    "    # Compute gradients using finite differences\n",
    "    dy_true = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
    "    dx_true = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
    "    dy_pred = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
    "    dx_pred = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
    "\n",
    "    # Pad the tensors to ensure they have the same dimensions\n",
    "    dy_true = F.pad(dy_true, (0, 0, 1, 0), mode='replicate')\n",
    "    dx_true = F.pad(dx_true, (1, 0, 0, 0), mode='replicate')\n",
    "    dy_pred = F.pad(dy_pred, (0, 0, 1, 0), mode='replicate')\n",
    "    dx_pred = F.pad(dx_pred, (1, 0, 0, 0), mode='replicate')\n",
    "\n",
    "    l_edges = torch.mean(torch.abs(dy_pred - dy_true) + torch.abs(dx_pred - dx_true))\n",
    "\n",
    "    # Normalize y_true and y_pred to the range [0, 1]\n",
    "    y_true_norm = (y_true - y_true.min()) / (y_true.max() - y_true.min())\n",
    "    y_pred_norm = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())\n",
    "\n",
    "    l_ssim = torch.clip((1 - piq.ssim(y_true_norm, y_pred_norm, data_range=1.0)) * 0.5, 0, 1)\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * l_edges) + (w3 * l_depth)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=INIT_LR, amsgrad=True)\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, depth_maps in training_loader:\n",
    "        images, depth_maps = images.to(device).float(), depth_maps.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = depth_loss(depth_maps, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(training_loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0.0\n",
    "    for images, depth_maps in test_loader:\n",
    "        images, depth_maps = images.to(device).float(), depth_maps.to(device).float()\n",
    "        outputs = model(images)\n",
    "        loss = depth_loss(depth_maps, outputs)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss/len(test_loader)}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"./model1.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
